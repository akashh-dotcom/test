<?xml version="1.0" encoding="UTF-8"?>
<sect1 id="ch0031s0005">
   <sect1info>
      <risinfo>
         <risprev>sect1.9781394211319.ch0031s0004</risprev>
         <riscurrent>sect1.9781394211319.ch0031s0005</riscurrent>
         <risnext>sect1.9781394211319.ch0031s0006</risnext>
         <booktitle>HEALTH BEHAVIOR</booktitle>
         <isbn>9781394211319</isbn>
         <chapternumber/>
         <chapterid>ch0031</chapterid>
         <chaptertitle>KEY POINTS</chaptertitle>
         <authorgroup>
            <author>
               <personname>
                  <firstname>Karen</firstname>
                  <surname>Glanz</surname>
               </personname>
            </author>
            <author>
               <personname>
                  <firstname>Barbara K.</firstname>
                  <surname>Rimer</surname>
               </personname>
            </author>
            <author>
               <personname>
                  <firstname>K.</firstname>
                  <surname>Viswanath</surname>
               </personname>
            </author>
         </authorgroup>
         <publisher>
            <publishername>John Wiley &amp; Sons, Inc</publishername>
         </publisher>
         <pubdate>2024</pubdate>
      </risinfo>
      <primaryauthor>
         <personname>
            <firstname>Karen</firstname>
            <surname>Glanz</surname>
         </personname>
      </primaryauthor>
   </sect1info>
   <title>Study Designs and Methodological Approaches in Dissemination and Implementation Science: Some Considerations</title>
   <anchor id="ch0031s0005a0001"/>
   <anchor id="ch0031s0000a0042"/>
   <para id="ch0031s0000p0042">Dissemination and implementation research focuses primarily on understanding and supporting the spread and utilization of innovations and EBIs, as distinct from efficacy and effectiveness research, which focuses mainly on studying the impact of intervention strategies on health behaviors, health status, and other outcomes of interest. Dissemination and implementation studies seek to understand the roles of contextual factors, implementation strategies, and implementation outcomes at multiple levels (Mazzucca et al.,<link linkend="ch0031s0000li0069">2018</link>). Thus, it is useful to understand the types of study designs and methods used in dissemination and implementation science. While a full discussion of research methods for dissemination and implementation is beyond the scope of this chapter, we highlight some key considerations for readers.</para>
   <para id="ch0031s0000p0043">As one example, implementation strategies evaluated might address barriers to implementation at multiple levels (e.g., training to address teachers’ low knowledge and self‐efficacy to deliver the intervention, and organizational resources to facilitate school readiness to implement an EBI) and implementation success might be evaluated at multiple levels (e.g., among students, teachers, and principals). Increasingly, effectiveness and implementation are studied simultaneously using hybrid effectiveness‐implementation trials to make it possible to learn about implementation and to what extent the EBIs/innovations achieve the intended results in different contexts and/or when adapted for different populations (Curran et al.,<link linkend="ch0031s0000li0036">2012</link>).</para>
   <anchor id="ch0031s0000a0043"/>
   <beginpage pagenum="211"/>
   <para id="ch0031s0000p0044">Dissemination and implementation researchers use a variety of study designs to ensure that their evaluations reflect real‐world settings and <ulink type="disease" url="link.aspx?id=10321">stakeholders</ulink>, often with the “cluster” or organizational setting as the main focus (Brown et al.,<link linkend="ch0031s0000li0025">2017</link>; Mazzucca et al., <link linkend="ch0031s0000li0069">2018</link>). Thus, for example, randomized controlled trials (RCTs) of individuals may not be feasible or optimal for dissemination and implementation research. Instead, other designs may be helpful, such as stepped wedge trials. With this design, every site or organization receives the implementation strategy and EBI, but the timing at which they receive it is randomized and staggered. This design, like that of a delayed control group, preserves the focus on assessing outcomes at the site level but also helps avoid ethical concerns due to withholding a beneficial treatment or program (e.g., an EBI that has been found to be effective). Additionally, staggering timing of delivery of implementation strategies and EBIs can address some of the logistical challenges of implementation across a large number of sites or “clusters” (e.g., conducting an implementation trial nationally across 60 <ulink type="disease" url="link.aspx?id=10343">primary care</ulink> practices). A review of recent dissemination and implementation science studies offers a helpful overview of relevant study designs (Mazzucca et al., <link linkend="ch0031s0000li0069">2018</link>).</para>
   <para id="ch0031s0000p0045">Mixed‐method designs that combine and integrate qualitative and quantitative data are becoming increasingly common in dissemination and implementation science. With these designs, qualitative methods support the exploration of phenomena of interest (e.g., implementation context), and quantitative methods allow for testing hypotheses (e.g., which implementation strategies are effective?) (Curran et al.,<link linkend="ch0031s0000li0036">2012</link>). Reviews and guides of mixed‐methods dissemination and implementation research offer additional insight and guidance in applying these approaches rigorously (Palinkas et al., <link linkend="ch0031s0000li0083">2011</link>; QualRIS Group, <link linkend="ch0031s0000li0087">2019</link>).</para>
</sect1>
